# **Mini-Agentic-AI**

[Loom Video](https://www.loom.com/share/343ec0d686e54b30a592c46d728ade2a)

This project is an AI-powered query pipeline using **LangChain, Google Gemini AI, Pinecone, and Streamlit** for an interactive query-handling web app.  

## **ğŸš€ Features**  

âœ… **Query Classification** â€“ Automatically classifies queries into "weather", "rag", or "general".  

âœ… **Weather API Integration** â€“ Retrieves real-time weather information using OpenWeather API.  

âœ… **Document Retrieval (RAG)** â€“ Uses **Pinecone** and **Google Generative AI embeddings** to retrieve relevant documents for answering queries.  

âœ… **General Query Handling** â€“ Uses Gemini AI to answer open-ended questions.  

âœ… **LangGraph Workflow** â€“ Implements a **decision-based pipeline** for intelligent query handling.  

âœ… **Langsmith Workflow** - Implement Langsmith for evaluate LLM model performance.   

âœ… **Test Cases** - Implement Pytest workflow for test all Function poperly work or not.   

âœ… **Streamlit UI** â€“ Provides a simple, interactive web app for query input and responses.  

---

## **ğŸ› ï¸ Setup Instructions**  

### **1ï¸âƒ£ Clone the Repository**  

```bash
git clone https://github.com/ritwiks9635/Mini-Agentic-AI.git
cd Mini-Agentic-AI
```

### **2ï¸âƒ£ Create a Virtual Environment (Optional but Recommended)**  

```bash
python -m venv venv
source venv/bin/activate  # On macOS/Linux
venv\Scripts\activate  # On Windows
```

### **3ï¸âƒ£ Install Dependencies**  

```bash
pip install -r requirements.txt
```

### **4ï¸âƒ£ Set Up API Keys**  

1. **Create a `.env` file** in the project root and add the following keys:  

   ```env
   OPENWEATHER_API_KEY=your_openweather_api_key
   PINECONE_API_KEY=your_pinecone_api_key
   GOOGLE_GEMINI_API_KEY=your_gemini_api_key
   ```

2. **Ensure `.env` is added to `.gitignore`** to prevent pushing sensitive information.  

---

## **ğŸ”§ Implementation Details**  

### **ğŸ“‚ Project Structure**  

```
ğŸ“¦ project-root
â”‚â”€â”€ ğŸ“‚ pipeline
â”‚   â”œâ”€â”€ pipeline.py   # Main LangGraph workflow
â”œâ”€â”€ app.py        # Streamlit UI
â”‚â”€â”€ .env              # Stores API keys (not pushed to GitHub)
â”‚â”€â”€ .gitignore        # Ensures .env is ignored
â”‚â”€â”€ requirements.txt  # Dependencies
â”‚â”€â”€ README.md         # Project documentation
```

### **ğŸ§© How It Works**  

1. **Query is classified** using Gemini AI into:
   - `weather` (fetches weather data)
   - `rag` (retrieves relevant documents from Pinecone)
   - `general` (answers the question directly using Gemini AI)  

2. **Weather Queries** â€“ Uses OpenWeather API to fetch real-time weather information.  

3. **RAG Queries** â€“  
   - Loads **PDF documents** using `PyPDFLoader`.  
   - Splits text into chunks using `RecursiveCharacterTextSplitter`.  
   - Stores embeddings in **Pinecone**.  
   - Retrieves relevant documents and generates an answer.  

4. **General Queries** â€“ Uses Gemini AI to generate informative responses.  

5. **Streamlit Web App (`app.py`)**  
   - Users enter queries via a simple UI.  
   - Displays query classification and response.  

---

## **ğŸ–¥ï¸ Running the Project**  

### **Run the LangChain Pipeline**  

```bash
python pipeline/pipeline.py
```

### **Run the Streamlit Web App**  

```bash
streamlit run app.py
```

Then, open the link displayed in the terminal to access the app.  

---

## **ğŸ“Œ Future Enhancements**  
- Add a chatbot UI with Streamlit.  
- Support for voice queries.  
- Multi-document support.  

---

## **ğŸ“œ License**  

This project is licensed under the **MIT License**.  
